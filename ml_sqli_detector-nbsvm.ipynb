{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic classifier that uses Distilbert model to predict if the payload is an SQL injection\n",
    "##### Distilbert is a smaller and faster version of BERT ( Bidirectional Encoder Representations from Transformers) that is 40% lighter while retaining 97% of BERT's language understanding ability. More on Distilbert at [HuggingFace](https://huggingface.co/docs/transformers/model_doc/distilbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To begin, let's install and import some packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9o-dl8wLv3Ep"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: ktrain in /usr/local/lib/python3.8/site-packages (0.31.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/site-packages (2.6.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (1.19.5)\n",
      "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.8/site-packages (from ktrain) (0.89.0)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.8/site-packages (from ktrain) (4.0.0)\n",
      "Requirement already satisfied: syntok==1.3.3 in /usr/local/lib/python3.8/site-packages (from ktrain) (1.3.3)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/site-packages (from ktrain) (0.1.96)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from ktrain) (21.3)\n",
      "Requirement already satisfied: cchardet in /usr/local/lib/python3.8/site-packages (from ktrain) (2.1.7)\n",
      "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.8/site-packages (from ktrain) (1.0.2)\n",
      "Requirement already satisfied: whoosh in /usr/local/lib/python3.8/site-packages (from ktrain) (2.7.4)\n",
      "Requirement already satisfied: scikit-learn==0.24.2 in /usr/local/lib/python3.8/site-packages (from ktrain) (0.24.2)\n",
      "Requirement already satisfied: langdetect in /usr/local/lib/python3.8/site-packages (from ktrain) (1.0.9)\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.8/site-packages (from ktrain) (0.42.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.8/site-packages (from ktrain) (1.2.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from ktrain) (2.25.1)\n",
      "Requirement already satisfied: transformers==4.10.3 in /usr/local/lib/python3.8/site-packages (from ktrain) (4.10.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/site-packages (from ktrain) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/site-packages (from scikit-learn==0.24.2->ktrain) (1.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn==0.24.2->ktrain) (3.0.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.8/site-packages (from syntok==1.3.3->ktrain) (2022.4.24)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.8/site-packages (from transformers==4.10.3->ktrain) (0.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/site-packages (from transformers==4.10.3->ktrain) (3.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from transformers==4.10.3->ktrain) (5.4.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/site-packages (from transformers==4.10.3->ktrain) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/site-packages (from transformers==4.10.3->ktrain) (4.62.3)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/site-packages (from transformers==4.10.3->ktrain) (0.0.53)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib) (8.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /usr/local/lib/python3.8/site-packages (from matplotlib) (6.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/site-packages (from matplotlib) (4.28.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.8/site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: keras-transformer==0.40.0 in /usr/local/lib/python3.8/site-packages (from keras-bert>=0.86.0->ktrain) (0.40.0)\n",
      "Requirement already satisfied: keras-multi-head==0.29.0 in /usr/local/lib/python3.8/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.29.0)\n",
      "Requirement already satisfied: keras-pos-embd==0.13.0 in /usr/local/lib/python3.8/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.13.0)\n",
      "Requirement already satisfied: keras-position-wise-feed-forward==0.8.0 in /usr/local/lib/python3.8/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.8.0)\n",
      "Requirement already satisfied: keras-embed-sim==0.10.0 in /usr/local/lib/python3.8/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: keras-layer-normalization==0.16.0 in /usr/local/lib/python3.8/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.16.0)\n",
      "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.8/site-packages (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.51.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/site-packages (from pandas>=1.0.1->ktrain) (2021.3)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib) (59.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->ktrain) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->ktrain) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->ktrain) (2021.10.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/site-packages (from sacremoses->transformers==4.10.3->ktrain) (8.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn>=1.0.0\n",
    "!pip3 install ktrain matplotlib tensorflow numpy\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some more imports...We are using ktrain wrapper to simplify model operations and take advantage of some cool stuff like simplified data set preprocessing, learning rate finding and \"autofit\" that ensures the model is not overfit. More details on ktrain here: [ktrain on GitHub](https://github.com/amaiya/ktrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "evreWp_bv3Es"
   },
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's print the list of available text classifiers in ktrain. There are relatively simple models like fasttext or bigru that have only 7-10 layers, as well as some more sophisticated deep models like BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext: a fastText-like model [http://arxiv.org/pdf/1607.01759.pdf]\n",
      "logreg: logistic regression using a trainable Embedding layer\n",
      "nbsvm: NBSVM model [http://www.aclweb.org/anthology/P12-2018]\n",
      "bigru: Bidirectional GRU with pretrained fasttext word vectors [https://fasttext.cc/docs/en/crawl-vectors.html]\n",
      "standard_gru: simple 2-layer GRU with randomly initialized embeddings\n",
      "bert: Bidirectional Encoder Representations from Transformers (BERT) from keras_bert [https://arxiv.org/abs/1810.04805]\n",
      "distilbert: distilled, smaller, and faster BERT from Hugging Face transformers [https://arxiv.org/abs/1910.01108]\n"
     ]
    }
   ],
   "source": [
    "text.print_text_classifiers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Shmkj8niv3Ev"
   },
   "source": [
    "### Here, we will load our data set. \n",
    "##### We have a CSV file ``trainlist_22k.csv`` that contains a list of HTTP paths that are labeled according to their association with cross-site scripting (xss) and sql injection (sqli).  There is also a \"regular\" traffic that belongs to a \"benign\" class. Data set load is performed using the ```texts_from_csv``` method, which assumes the label_columns are already one-hot-encoded in the spreadsheet. Since *val_filepath* is None, 10% of the data will automatically be used as a validation set.\n",
    "##### In our set we have: 1 feature (payload), 1 label (type) that contains 3 classes:\n",
    " - xss\n",
    " - sqli\n",
    " - benign\n",
    "\n",
    "##### We will be using Distilbert model so preprocessing mode is set to ``Distilbert``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j6-wA79wv3Ew",
    "outputId": "7f7ba49d-d58f-4cf3-f363-806f37d2bd99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected encoding: UTF-8-SIG (if wrong, set manually)\n",
      "['attack', 'normal']\n",
      "        attack  normal\n",
      "907919     0.0     1.0\n",
      "265451     0.0     1.0\n",
      "373061     0.0     1.0\n",
      "696603     0.0     1.0\n",
      "716496     0.0     1.0\n",
      "['attack', 'normal']\n",
      "        attack  normal\n",
      "940585     0.0     1.0\n",
      "560463     0.0     1.0\n",
      "133169     0.0     1.0\n",
      "618650     0.0     1.0\n",
      "630044     0.0     1.0\n",
      "language: en\n",
      "Word Counts: 568743\n",
      "Nrows: 943312\n",
      "943312 train sequences\n",
      "train sequence lengths:\n",
      "\tmean : 1\n",
      "\t95percentile : 5\n",
      "\t99percentile : 13\n",
      "x_train shape: (943312,200)\n",
      "y_train shape: (943312, 2)\n",
      "Is Multi-Label? False\n",
      "104813 test sequences\n",
      "test sequence lengths:\n",
      "\tmean : 1\n",
      "\t95percentile : 5\n",
      "\t99percentile : 13\n",
      "x_test shape: (104813,200)\n",
      "y_test shape: (104813, 2)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'dataset_new.csv'\n",
    "NUM_WORDS = 500\n",
    "MAXLEN = 200\n",
    "trn, val, preproc = text.texts_from_csv(DATA_PATH,\n",
    "                      'payload',\n",
    "                      label_columns = [\"type\"],\n",
    "                      val_filepath=None, # if None, 10% of data will be used for validation\n",
    "                      max_features=NUM_WORDS, maxlen=MAXLEN,\n",
    "                      ngram_range=1,\n",
    "                      preprocess_mode='standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load the learner instance that uses ```Distilbert``` model. We will retain the model structure unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "UpbaZ68Dv3Ew",
    "outputId": "68874f80-6a80-4960-a152-1b594f4ee856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "compiling word ID features...\n",
      "maxlen is 200\n",
      "building document-term matrix... this may take a few moments...\n",
      "rows: 1-10000\n",
      "rows: 10001-20000\n",
      "rows: 20001-30000\n",
      "rows: 30001-40000\n",
      "rows: 40001-50000\n",
      "rows: 50001-60000\n",
      "rows: 60001-70000\n",
      "rows: 70001-80000\n",
      "rows: 80001-90000\n",
      "rows: 90001-100000\n",
      "rows: 100001-110000\n",
      "rows: 110001-120000\n",
      "rows: 120001-130000\n",
      "rows: 130001-140000\n",
      "rows: 140001-150000\n",
      "rows: 150001-160000\n",
      "rows: 160001-170000\n",
      "rows: 170001-180000\n",
      "rows: 180001-190000\n",
      "rows: 190001-200000\n",
      "rows: 200001-210000\n",
      "rows: 210001-220000\n",
      "rows: 220001-230000\n",
      "rows: 230001-240000\n",
      "rows: 240001-250000\n",
      "rows: 250001-260000\n",
      "rows: 260001-270000\n",
      "rows: 270001-280000\n",
      "rows: 280001-290000\n",
      "rows: 290001-300000\n",
      "rows: 300001-310000\n",
      "rows: 310001-320000\n",
      "rows: 320001-330000\n",
      "rows: 330001-340000\n",
      "rows: 340001-350000\n",
      "rows: 350001-360000\n",
      "rows: 360001-370000\n",
      "rows: 370001-380000\n",
      "rows: 380001-390000\n",
      "rows: 390001-400000\n",
      "rows: 400001-410000\n",
      "rows: 410001-420000\n",
      "rows: 420001-430000\n",
      "rows: 430001-440000\n",
      "rows: 440001-450000\n",
      "rows: 450001-460000\n",
      "rows: 460001-470000\n",
      "rows: 470001-480000\n",
      "rows: 480001-490000\n",
      "rows: 490001-500000\n",
      "rows: 500001-510000\n",
      "rows: 510001-520000\n",
      "rows: 520001-530000\n",
      "rows: 530001-540000\n",
      "rows: 540001-550000\n",
      "rows: 550001-560000\n",
      "rows: 560001-570000\n",
      "rows: 570001-580000\n",
      "rows: 580001-590000\n",
      "rows: 590001-600000\n",
      "rows: 600001-610000\n",
      "rows: 610001-620000\n",
      "rows: 620001-630000\n",
      "rows: 630001-640000\n",
      "rows: 640001-650000\n",
      "rows: 650001-660000\n",
      "rows: 660001-670000\n",
      "rows: 670001-680000\n",
      "rows: 680001-690000\n",
      "rows: 690001-700000\n",
      "rows: 700001-710000\n",
      "rows: 710001-720000\n",
      "rows: 720001-730000\n",
      "rows: 730001-740000\n",
      "rows: 740001-750000\n",
      "rows: 750001-760000\n",
      "rows: 760001-770000\n",
      "rows: 770001-780000\n",
      "rows: 780001-790000\n",
      "rows: 790001-800000\n",
      "rows: 800001-810000\n",
      "rows: 810001-820000\n",
      "rows: 820001-830000\n",
      "rows: 830001-840000\n",
      "rows: 840001-850000\n",
      "rows: 850001-860000\n",
      "rows: 860001-870000\n",
      "rows: 870001-880000\n",
      "rows: 880001-890000\n",
      "rows: 890001-900000\n",
      "rows: 900001-910000\n",
      "rows: 910001-920000\n",
      "rows: 920001-930000\n",
      "rows: 930001-940000\n",
      "rows: 940001-943312\n",
      "computing log-count ratios...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, GaussianDropout, Flatten, LSTM, Embedding, GRU, SimpleRNN\n",
    "\n",
    "def get_model():\n",
    "    model = text.text_classifier('nbsvm', (trn), \n",
    "                             preproc=preproc)\n",
    "    #model.add(Dense(3, activation='sigmoid'))\n",
    "    #model.add(GaussianDropout1D(0.2))\n",
    "    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "nbsvm_model = get_model()\n",
    "new_model = Sequential()\n",
    "new_model.add(nbsvm_model)\n",
    "new_model.add(Embedding(input_dim=500, output_dim=64))\n",
    "new_model.add(LSTM(64))\n",
    "#new_model.add(GRU(256, return_sequences=True))\n",
    "#new_model.add(SimpleRNN(128))\n",
    "#new_model.add(concatenate([text_features]))\n",
    "new_model.add(Dense(16, activation='sigmoid'))\n",
    "new_model.add(GaussianDropout(0.2))\n",
    "new_model.add(Dense(2, activation='sigmoid'))\n",
    "new_model.add(Flatten())\n",
    "#new_model=nbsvm_model\n",
    "new_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "learner = ktrain.get_learner(new_model, train_data=(trn), val_data=(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is what our model looks like. It has a number of layers that are pre-trained therefore allowing us to leverage transfer learning.\n",
    "##### Source code for modeling_tf_distilbert can be found at [HuggingFace Transformers](https://huggingface.co/transformers/v2.3.0/_modules/transformers/modeling_tf_distilbert.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fh1_l7ioIpS6",
    "outputId": "c35e8957-540f-42a7-fd07-d9d417915873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (trainable=True) : <keras.engine.functional.Functional object at 0x7fb65a092100>\n",
      "1 (trainable=True) : <keras.layers.embeddings.Embedding object at 0x7fb65a0924f0>\n",
      "2 (trainable=True) : <keras.layers.recurrent_v2.LSTM object at 0x7fb68f258d60>\n",
      "3 (trainable=True) : <keras.layers.core.Dense object at 0x7fb62899b400>\n",
      "4 (trainable=True) : <keras.layers.noise.GaussianDropout object at 0x7fb658e456d0>\n",
      "5 (trainable=True) : <keras.layers.core.Dense object at 0x7fb61048cdf0>\n",
      "6 (trainable=True) : <keras.layers.core.Flatten object at 0x7fb65908d7f0>\n"
     ]
    }
   ],
   "source": [
    "learner.print_layers()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to ensure that majority of existing pre-trained layers are not re-trained so we are freezing those with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ATgiIbyE7XJ"
   },
   "outputs": [],
   "source": [
    "learner.freeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The optimal learning rate for this model can be found using the **lr_find** function however it will take at least **20 minutes!** on this VM that uses CPU only. ( Optimal rate was found to be 3e-5 and therefore there is no need to spend time on this now). **If you still want to proceed**, uncomment the command and run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "u-kza8Env3Ex",
    "outputId": "146052d1-5d60-4708-b878-1660db206379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Epoch 1/50\n",
      "29/29 [==============================] - 2s 4ms/step - loss: 0.6192 - accuracy: 0.8053\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6187 - accuracy: 0.7942\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6155 - accuracy: 0.7864\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.7898\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.7775\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.7798\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.7842\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6193 - accuracy: 0.7875\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.7898\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6178 - accuracy: 0.8065\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.8031\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.8053\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.8131\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.7909\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.8087\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.8165\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.8276\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.8476\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.8665\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.9032\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.9444\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.9544\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.9544\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2369 - accuracy: 0.9544\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2294 - accuracy: 0.9544\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2221 - accuracy: 0.9544\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2157 - accuracy: 0.9544\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2076 - accuracy: 0.9544\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2024 - accuracy: 0.9544\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1965 - accuracy: 0.9544\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1977 - accuracy: 0.9544\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1943 - accuracy: 0.9544\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9544\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1983 - accuracy: 0.9544\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1893 - accuracy: 0.9544\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1946 - accuracy: 0.9544\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1960 - accuracy: 0.9544\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1951 - accuracy: 0.9544\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1939 - accuracy: 0.9544\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2047 - accuracy: 0.9544\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1959 - accuracy: 0.9544\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2160 - accuracy: 0.9544\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1999 - accuracy: 0.9544\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9544\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2190 - accuracy: 0.9544\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2035 - accuracy: 0.9544\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.9466\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3629 - accuracy: 0.9277\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.9399\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6995 - accuracy: 0.9544\n",
      "\n",
      "\n",
      "done.\n",
      "Visually inspect loss plot and select learning rate associated with falling loss\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAArJklEQVR4nO3deXxddZ3/8dfn3uz72iVb94WWtpSGym5RRAQtmwVxRVGGGXHXEQaHGdERHdT5KaIDiIOoUMoqIlBFdum+7/uStE2aZm/2m3x/f9ybGto0TSA3J8l5Px+PPMw999xzPjmW877f8z3n+zXnHCIi4l8BrwsQERFvKQhERHxOQSAi4nMKAhERn1MQiIj4nIJARMTnYrwuoK9ycnLc2LFjvS5DRGRIWbVq1RHnXG537w25IBg7diwrV670ugwRkSHFzPad7D1dGhIR8TkFgYiIzykIRER8TkEgIuJzCgIREZ9TEIiI+NyQu310uHLOUXG0hR3lRxmVnoBzjrTEWHJT4jEzr8sTkWHMN0GwvrSG5XuqOHt8NtNGpxEI9M/JtTXUQXldMwWZicdO2G3tHRyqaaaqsZVxOcmkJ8binKO2qY3dRxrYUV5PSVUTdc1tlNc1U1LVxL7KBhpa20/Yfkp8DKeNTmVmQQZjspNIjoshKS5IYlyQxNggGw/WsefIUc6bkMPccVmkJcYSGwxwuL6Z17ZVkBQXw5jsJMbnJpMU55v/u0WkD3xzZnhjxxHuXrwNgPTEWAoyE0lNiOEn155BfkZin7bV3uFYsquSp9cc4MWNh2hobScrOY7E2CAtoQ6qG1tp7/jHhD/xMQHaOxyhjrdPApSWEMOItAQKMhOZOy6LsdlJFGYlUdXQSlxMgJrGNnZVHGXjgVp+v3QfLaGObuuJCwb4/dL9x16nJ8YSau84IVhyUuIoyEzi7PHZfHjmaKbnpam1ISLYUJuhrLi42L3TJ4sP1TaxdHcly/dUs6+ygbd2VZKeGMvH5hYyMTeF5lAHB2uaiAsGuO6sQkalJdDhHA0t7dS3tFHXFOKZtQd4Zs0BDte3kBofw4dmjCIpLobyumYSY4PExwbJTo6jKCuJhLgge480cLQlRDBgZCfHMS4nmdHpiYzPTSYhNtjr2js6HJUNrTS0hGhqa6extZ2m1nYS4wLMLMhg9b5qNh6so6ElxJGjLTS1tvPx9xQRFxNgX2UjuyuOcqCmiV0VDazeV02owzE2O4lLpo9i0ogUxmQn0xIKb7cl1EFSbJCCrETGZifT1t6BA0LtjtZQB23tHbSEOoiPCRAMGA0tIZrbOoiLCZCeGEtGUizBgBEbPLELqqy2mdX7q8lIimXKyFSyU+Lf0f+XItI3ZrbKOVfc7Xt+CoLj7Siv578Xb+OlLeV0HoZgwI59m+/6e6eYgHHR1BFcNTuf900d0aeT+WBR3dDK4k1lPLf+EEt3V57QUukvuanxTMhNZs6YTOaMyaTyaCu3P7OR1i4tm1FpCVw8bQTf+MAUMpPjolKHiCgITqmhJUTl0fDlmNzUeLaX17NyXzWHapqIjwmSkhBDanwMMUGjeEwWRdlJ/bp/L4XaOyitbmJPZQNJsUGS42NIiA1wtKWd/VXhlkRsMEBcMEBM0IiPCRIbNOJiAjS0tBMwIp8J0hJqp64pRE1TKy1tHZTVNrO1rI5NB+uOhc3ccVncftlp1DW3sa2snlX7qlm8qYxzJ+Rw/6fnqB9DJEoUBOKpptZ21pfWUFbXzIdOH01czNsvGT26fD+3PbWBtIQYFhQXcsO5YynMGj5hKzIYKAhk0Fu1r4qH3trHCxsO4YDLZ4zmS++byKSRqV6XJjIs9BQEUX2gzMwuNbNtZrbTzG49yTrXmtlmM9tkZo9Esx4ZvOaMyeKe62fz+r9exOfOG8vftpRzyf97nZ/8ZRtD7cuKyFATtRaBmQWB7cAHgFJgBXC9c25zl3UmAYuA9znnqs1shHPucE/bVYvAH6oaWvmvP2/hydWlfOrsMdzxkWnd3oUkIr3TU4sgmj1zc4GdzrndkSIWAlcAm7us8wXgXudcNcCpQkD8Iys5jrs/OpOs5FgeeGMPGw7U8uMFs5g4IsXr0kSGnWh+xcoHSrq8Lo0s62oyMNnM/m5mS83s0ijWI0NMIGDcfvk0fvHx2eytbOCyn7/Bfa/tOuGWXhF5d7xua8cAk4B5wPXAA2aWcfxKZnaTma00s5UVFRUDW6F47sMz8/jr197LRVNyueuFrVz9q7fYXl7vdVkiw0Y0g+AAUNjldUFkWVelwLPOuTbn3B7CfQqTjt+Qc+5+51yxc644N7fbuZdlmMtNjed/PzmHe66fTUlVI5f//A2eXXfQ67JEhoVoBsEKYJKZjTOzOOBjwLPHrfMM4dYAZpZD+FLR7ijWJEOYmfGRWXn89WsXMrsok68uXMPTa0q9LktkyItaEDjnQsAtwGJgC7DIObfJzO40s/mR1RYDlWa2GXgF+JZzrjJaNcnwkJ0Sz0OfPYv3jMvm64vWsXD5/lN/SEROSg+UyZDV1NrOP/1+Fa9vr+CLF03gm5dM0WiqIifh2QNlItGUGBfkwc8Uc/3cQu59ZRe3PrlBdxSJvAMa4UuGtNhggB9cNYPclHh+/vJOAgG46+qZXpclMqSoRSBDnpnx9UumcMO5Y3lsRQkHapq8LklkSFEQyLBx4/njcMBj6jwW6RMFgQwbhVlJzJucyyPL99PUzfzPItI9BYEMK/88byJHjrby+6X7vC5FZMhQEMiwMndcFudNzOZ/X9tFY2vI63JEhgQFgQw7X7t4MpUNrfxuiVoFIr2hIJBhp3hsFhdMyuG+13erVSDSCwoCGZa+evFkqhpaeVitApFTUhDIsDRnTCYXTs7lgdd309ymO4hEeqIgkGHr5veOp7KhlafXHD/6uYh0pSCQYeuc8dlMz0vjgTd206ExiEROSkEgw5aZcdOF49ld0cAr2zQdtsjJKAhkWLtsxmhGpyfwwBua70jkZBQEMqzFBgNcd1YhS3dXUdvY5nU5IoOSgkCGvbljswBYW1rjbSEig5SCQIa9mYUZBAxW76v2uhSRQUlBIMNeSnwMk0aksuFArdeliAxKCgLxhel5aWxUEIh0S0EgvjA9P53D9S0crm/2uhSRQUdBIL4wPS8NgE0H6zyuRGTwURCIL0yLBMFmBYHICRQE4gtpCbGMyU5SP4FINxQE4hun56Wz8aCCQOR4CgLxjen5aZRUNekJY5HjKAjEN6bnpQOw6ZBaBSJdKQjEN6arw1ikWwoC8Y2clHhGpSWow1jkOAoC8ZXpeWl6lkDkOAoC8ZXpeWnsqjhKU6vmMRbppCAQX5mWl06Hg61lahWIdFIQiK9oqAmREykIxFcKMhNJT4xVEIh0oSAQXzEzpo1OY7OeMBY5JqpBYGaXmtk2M9tpZrd28/4NZlZhZmsjP5+PZj0iEL48tLWsnlB7h9eliAwKUQsCMwsC9wIfAqYB15vZtG5Wfcw5d0bk59fRqkek0/T8NFpCHeyqaPC6FJFBIZotgrnATufcbudcK7AQuCKK+xPplWNDTejykAgQ3SDIB0q6vC6NLDveNWa23syeMLPCKNYjAsD4nGTiYwLqMBaJ8Lqz+E/AWOfcTOCvwG+7W8nMbjKzlWa2sqKiYkALlOEnJhhg6ug0tQhEIqIZBAeArt/wCyLLjnHOVTrnWiIvfw3M6W5Dzrn7nXPFzrni3NzcqBQr/jI9L43NB+twznldiojnohkEK4BJZjbOzOKAjwHPdl3BzEZ3eTkf2BLFekSOmZ6XRl1ziNLqJq9LEfFcTLQ27JwLmdktwGIgCPzGObfJzO4EVjrnngW+bGbzgRBQBdwQrXpEuuraYVyYleRxNSLeiloQADjnngeeP27ZHV1+vw24LZo1iHRn6qhUggFj08E6Lj199Kk/IDKMed1ZLOKJhNggE3KTdeeQCAoC8bHpeem6c0gEBYH42PS8NMrrWqg82nLqlUWGMQWB+Na4nGQASnTnkPicgkB8Ky8jEYCDNQoC8TcFgfhWZxAcUItAfE5BIL6VlhBDSnwMB9QiEJ9TEIhvmRl5GQm6NCS+pyAQX8vPSFRnsfiegkB8rSgridKqRg0+J76mIBBfK8pOpr4lRHVjm9eliHhGQSC+VhQZcG5/VaPHlYh4R0EgvjYmW0EgoiAQXyvMjARBpSayF/9SEIivJcYFyU2NV4tAfE1BIL43JitJQSC+piAQ3yvKSmJ/pYJA/EtBIL5XmJXEobpmWkLtXpci4gkFgfjemOwknNPgc+JfCgLxvc5nCfapn0B8SkEgvtcZBCUKAvEpBYH4Xm5qPAmxAfapw1h8SkEgvmdm4TuH1CIQn1IQiBC+PKRLQ+JXCgIRoCgrmf0ajlp8SkEgAhRlJdLY2s6Ro61elyIy4BQEIkCRRiEVH1MQiBC+NASwv0qjkIr/KAhEgILMRAD2V+rpYvEfBYEIkBAbZFRagi4NiS8pCEQiirKTdGlIfElBIBKhh8rErxQEIhFFWUmU17XQ3KbhqMVfehUEZvYVM0uzsAfNbLWZXRLt4kQGUudE9hpzSPymty2Czznn6oBLgEzgU8APo1aViAcm5KYAsPPwUY8rERlYvQ0Ci/zvZcDvnHObuiw7+YfMLjWzbWa208xu7WG9a8zMmVlxL+sR6XcTR6RgBtvL670uRWRA9TYIVpnZXwgHwWIzSwU6evqAmQWBe4EPAdOA681sWjfrpQJfAZb1pXCR/pYQG6QoK0ktAvGd3gbBjcCtwFnOuUYgFvjsKT4zF9jpnNvtnGsFFgJXdLPe94AfAc29rEUkaiaNSGXHYbUIxF96GwTnANucczVm9kngO0DtKT6TD5R0eV0aWXaMmZ0JFDrn/tzLOkSiatLIFPYcaaCtvccGr8iw0tsg+BXQaGazgG8Au4CH382OzSwA/DSyvVOte5OZrTSzlRUVFe9mtyI9mjQihbZ2x75KPVgm/tHbIAi58EDtVwC/cM7dC6Se4jMHgMIurwsiyzqlAqcDr5rZXuBs4NnuOoydc/c754qdc8W5ubm9LFmk7yaPDP+z3l6ufgLxj94GQb2Z3Ub4ttE/R77Nx57iMyuASWY2zszigI8Bz3a+6Zyrdc7lOOfGOufGAkuB+c65lX3+K0T6yYTc8J1DOxQEMoi0hjr4xcs72HywLirb720QXAe0EH6eoIzwt/u7e/qAcy4E3AIsBrYAi5xzm8zsTjOb/y5qFomaxLgghZlJ6jCWQaW8rpkf/2U7Gw7URGX7Mb1ZyTlXZmZ/AM4ysw8Dy51zp+wjcM49Dzx/3LI7TrLuvN7UIhJtk0akqEUgg0p5XfimypFpCVHZfm+HmLgWWA4sAK4FlpnZR6NSkYjHJo5MYfeRo4R055AMEmWRIBiVHp0g6FWLALid8DMEhwHMLBd4CXgiKlWJeGjyiFTa2h1v7arkwsm6OUG8V1YbCQIvWwRAoDMEIir78FmRIeXMMZkALFyx3+NKRMLK65qJjwmQnniqe3Temd62CF40s8XAo5HX13HctX+R4WJcTjIfnjmaVfuqvS5FBICyuhZGpSdgdsoh3t6RXn2rd859C7gfmBn5ud859+2oVCQyCJxZlMmh2uZjTXIRL5XXNketoxh63yLAOfck8GTUKhEZRM4oygBgbUk1l6aP9rYY8b0DNU3MHZcVte332CIws3ozq+vmp97MovNkg8ggMG10GjEBY33pqYbUEomu9g5HWV0zeRketQicc6caRkJkWEqIDTJ5ZCobDigIxFuH65tp73DkZSRGbR+680fkJGYWpLPhQC3hYbZEvHGwJtxPlZeuIBAZcDMK0qlpbKOkqsnrUsTHDtaE//2pRSDigdmF4ecJVu/XbaTinX8EQfT6CBQEIicxZVQqqfExLN9b5XUp4mMHa5pITYghNSE6D5OBgkDkpIIB48wxmaxUEIiHDtQ0kx/Fy0KgIBDp0dxxWWwvP0pNY6vXpYhPHaxpimr/ACgIRHpUHBl3SMNNiFcO1TYxOkqjjnZSEIj0YFZhBrFBUz+BeKKxNUR1Y5taBCJeSogNMrMgg5V71SKQgdf5DIH6CEQ8Vjw2k/WlNTS3tXtdivjMQDxDAAoCkVM6a0wWbe2OdSU1XpciPjMQzxCAgkDklIrHhjuMV6rDWAbYwdpmAha9uYo7KQhETiEjKY7JI1NYtkcdxjKwDtY0MSI1gdhgdE/VCgKRXjhnfDYr9lTRGtKE9jJwws8QRLc1AAoCkV45b2IOTW3trNG4QxJlja0hvr5oLYfrmgfkYTLowwxlIn529oRsAgZ/33mE94zP9rocGcb+tO4gT60+QFwwwMHaZj44fVTU96kWgUgvpCXEMqswgzd3HvG6FBnmWiKXH6saWmkNdQxIi0BBINJL50/MYV1pLXXNbV6XIsNY5/MqR462AER9eAlQEIj02nkTc2jvcPzHHzd5XYoMY+V14QA4EHmGID9TLQKRQePMovDzBC9sPKTpKyVqDtWGA6AzEAqzkqK+TwWBSC/FxQT472tm0tzWwaaDdV6XI8PUgcj4QgCZSbGkRXFCmk4KApE+eP9pIwhYuFUgEg2dw0rAwFwWAgWBSJ9kp8RzwaRcnllzkI4OXR6S/tUa6uDI0RZS4sN39l81u2BA9qsgEOmja+YUcKCmiSW7K70uRYaZ8rpmnIPvXH4ae+66jBvPHzcg+1UQiPTRJdNGkpYQw6KVJV6XIsNMeV24f2BkegJmNmD7VRCI9FFCbJArZ+fzwsYyahv1TIH0n847hUZFebTR4ykIRN6Ba4sLaQ118Md1B7wuRYaRskiLYFgFgZldambbzGynmd3azfs3m9kGM1trZm+a2bRo1iPSX07PT+f0/DQeWbZfzxRIvymvayYuJkBGUvRvGe0qakFgZkHgXuBDwDTg+m5O9I8452Y4584A/hv4abTqEelvnzp7DFvL6jVhjfSbstpmRqUNbP8ARLdFMBfY6Zzb7ZxrBRYCV3RdwTnX9amcZEBfrWTImD8rn7SEGH63ZJ/XpcgwUVbXPOCXhSC6QZAPdL2tojSy7G3M7Itmtotwi+DLUaxHpF8lxoU7jRdvKqO2SZ3G8u6V1zUzIi1+wPfreWexc+5e59wE4NvAd7pbx8xuMrOVZrayoqJiYAsU6cGCOYW0hDr407qDXpciQ5xzjvJh2CI4ABR2eV0QWXYyC4Eru3vDOXe/c67YOVecm5vbfxWKvEun56cxdVQqj68q9boUGeLqmkI0t3UwagCGnT5eNINgBTDJzMaZWRzwMeDZriuY2aQuLy8HdkSxHpF+Z2Z8dE4B60pq2FFe73U5MoR13jo6cji1CJxzIeAWYDGwBVjknNtkZnea2fzIareY2SYzWwt8HfhMtOoRiZarZucTEzDufWWn16XIEHbsGQIPWgRRnbPYOfc88Pxxy+7o8vtXorl/kYGQnRLPguJCnlhVwp1Xnj4gwwbL8FNe683DZDAIOotFhoMFxQW0tTueVF+BvEOdLQJf3jUkMhycUZDBeROzuev5rcemGBTpi/K6ZjKTYomPCQ74vhUEIv0gEDB+dM1MOpzjwTf2eF2ODEHldc2edBSDgkCk3xRkJjH/jDweXb6f6oZWr8uRIaasrtmTjmJQEIj0q5vfO4GmtnYeWb7f61JkiCmrbfGkoxgUBCL9avLIVM6fmMPvl+4j1N7hdTkyRLS1d1DZ0MIIBYHI8PDpc8ZwqLaZv2097HUpMkRU1LfgnDe3joKCQKTfvW/qCEalJfCoLg9JL/3jYbKBv3UUFAQi/S4mGODaswp5bXsFJVWNXpcjQ0Dnw2S6a0hkGLnurPB4iwtXqFUgp7bz8FHMoCgryZP9KwhEoiA/I5FLpo3k4bf2UaVbSeUU1pXWMj4nmVSPhidREIhEyTcumUJDa0iD0UmPmtvaWbLrCGeNzfKsBgWBSJRMHpnKxaeNZPGmMq9LkUHste0VNLS2c9mM0Z7VoCAQiaK547IorW5ilSa4l240tIT44QtbGZ2ewDkTsj2rQ0EgEkVXzc4nMymWO5/bTEeH87ocGWRe3nqYPUca+MHVM4gNenc6VhCIRFF2Sjy3Xz6NdSU1PLO2p5laxY82HKglLhjg/Ik5ntahIBCJsqtn5zOrIJ0fvbiVhpaQ1+XIILK1rJ5JI1M8bQ2AgkAk6gIB446PTKe8roVfvbrL63JkEDlU00RBZqLXZSgIRAbCnDGZXHFGHg+8sZvSaj1tLGFltc2MTlcQiPjGty+dCsDdi7d5XIkMBkdbQtS3hDybg6ArBYHIAMnLSOQLF4znj2sP6tkCoSwyvtBoBYGIv3zxoomcUZjBlx9dw7LdlV6XIx7qDAKvhp7uSkEgMoAS44L85oazyM9M5Obfr6KxVXcR+dXeygYA8tVZLOI/Wclx/OiamVQ3tvHkqlKvyxGPbDlUR2pCDPkZCgIRXyoek8kZhRn8+s09tOuJY1/adLCO00anYWZel6IgEPGCmXHze8ezr7KRh5fs9bocGWDNbe1sOljL7KIMr0sBIMbrAkT86oPTR3HRlFzuemErC5eXYAZXn5nPdcVFpCd5My69DIwNB2ppa3cUj/Fu6Omu1CIQ8YiZ8aNrZvKRmXmMzUkiNSGGHzy/lVl3/oWXNpefsH5LqJ2H/r6Hhcv363LSELdyb3g02jljMj2uJEwtAhEPjUhL4CfXzjr2+tVth7nh/1bw3ec2ccHkHOJjgsfeu+3JDTy1Jjxw3ZOrS/nxglmMyU4e8Jqlbx5Ztp+n15Sy6J/OOdYfsGpfFeNzkslKjvO4ujC1CEQGkXlTRvDbz82lpKqJ//jjJlpC7QA453hpSzlXz87nf66bxdayei7/+Zu8svWwxxVLTw7WNPFvT29gxd5qKupbAAi1d7BsT5WnM5IdT0EgMsi8d3IuN104noUrSvjUg8tpDXVQ3dhGXXOIaXlpXDW7gBe/eiFjspO48bcrePDNPTy9ppR/f2Yji1aUcDQywmlja4jdFUc9/mv87XvPbT72+4YDtQCsKamhvjnEe6fkelXWCXRpSGQQ+rfLTmPKyFS+8fg6ir//V+qawyf3cTnhS0H5GYk8fvM5fO2xtW872QD8z0vbufcTZ/Lzv+3g1W0VPPel8zk9P33A/wa/+/P6Q7ywsYyvXjyJ37y5hxc3lvH+00by2rYKggHjPI/nIOhKQSAySF0zp4CMpFgWbyojMTZIeV0LxV0uJyTFxfCrT8zh98v2MSI1notPG8nq/TV84/G1XHffEtrawx3KP3pxKw9/bu6guF/dL5pa27njjxuZkZ/OLRdNZOuhev629TCH65t5ZdthzizKID1x8NwZZs4NrbsPiouL3cqVK70uQ2TQqm1s42uL1vLy1sPEBQO0tnfwvStP51Nnj/G6NN94YlUp33x8HQtvOpuzx2eztayOK+/9O4mxQaob2/jO5afx+QvGD2hNZrbKOVfc3XtqEYgMM+lJsfz608X8dUs5swsz+OIjq/n3Zzaycm8V//mR6WRG7lRpaAmRFBeMekth6e5KnllzALPw07QzC9L57vzTCQaGbwvlsRX7GZ+TzHvGhVtwU0el8cOrZ/KNx9eRn5HIgjmFHlf4dlENAjO7FPgZEAR+7Zz74XHvfx34PBACKoDPOef2RbMmET8IBIwPTh8FwCNfOJtfvrKLe17ewVu7KvnPj0zncH0zdz63mXHZyVw2YzSXnj6KaaPTCPTzyXnRihK+/dR60hJicc5R1xxifWkt50/M4dLTR/frvgaLnYfrWbG3mts+NPVtIXvl7HzmTcklGDBSEwbPZSGI4qUhMwsC24EPAKXACuB659zmLutcBCxzzjWa2T8D85xz1/W0XV0aEnlnNh+s4+uL1rK1rB6ACbnJjExLYOnuSjoc5KbGc21xAd+8ZMoJrQTnHH/dXE5GUhxzx/XutseSqkbm/fhVzp2Qzf2fKiY2aKwrreWLf1jNyPQEnvmXc4dlv8X3n9vMQ2/tZem/vZ+clHivyzmmp0tD0bx9dC6w0zm32znXCiwErui6gnPuFedc57x9S4GCKNYj4mvT8tJ47kvn808Xjic2aPzqk3N45Atns+L2i/nxglkUZSVx7yu7eHVbxds+V9fcxicfXMZNv1vFtfct4cuPrqG5rf2U+/vDsv10OMcPr5lJYlyQmGCAOWMy+eL7JrKupIble6qi9ad6pqPD8eTqUi6ZPnJQhcCpRPPSUD5Q0uV1KfCeHta/EXghivWI+F5MMMBtl53GVy6eRFJc+D//7JR4PjqngPmz8jj7rr/x2YdWkJ+RSHxsgEM1zTRFTvo3XTiepLggP/vbDo4cbeGBTxeTHB9DS6idV7ZWMCY7iamjUjEz3txxhPte38X7p448YZjlBXMK+NlL2/nqY2u59UNT+cjMPDqc487nNhMMGP/6wan8Ydk+Xt1WQWFWEvNn5XHOhOwBP1bvxPbD9VQ3tnHxaSO9LqVPBkVnsZl9EigG3nuS928CbgIoKioawMpEhqfOEOgqLibAg58p5ndL9+Ec1Da1MW/yCMygKCuJz5w7FoAx2Ul88/H1fPyBpdx++TR++tdtLN0d/nY/dVQqH51TwGMrSshLT+QnC2adsJ+E2CD/+8k5fOeZjXxl4Vpuf3rjsYfgAP7v73sBmDQihTd3HmFdSQ3Pf+WC/j8IUdA5htBgGUyut6IZBAeArl3jBZFlb2NmFwO3A+91zrV0tyHn3P3A/RDuI+j/UkUEYHZRJrOLeh4I7arZBaTEx/K1x9Zy7X1LAPjO5acRHxPgidUH+P6ftwDwjQ9MPukoqsVjs3j+yxfw3IZDrNxbRVu7Y0RqPKkJMazeX81Vswu4+LQRfP/PW/jDsn10dLh+78iOhpV7q8hNjacwy/vJZvoimkGwAphkZuMIB8DHgI93XcHMZgP3AZc65zRoisgQ8YFpI3n+yxdwz8s7uHjayGN3KH3qnLHsKK/nrV2VLCjuucsvEDDmz8pj/qy8k64zPjeZ5rYODtY2UZCZ1K9/QzSs3l/DnKLMIdcJHrXOYudcCLgFWAxsARY55zaZ2Z1mNj+y2t1ACvC4ma01s2ejVY+I9K+i7CTuXjDrWAh0mjQylc+cO7bby099dWakddKbwfX2HmngtqfWM/bWP/PChkPvet99tfNwPfurGjljkEw20xdR7SNwzj0PPH/csju6/H5xNPcvIkPbaaPTmDoqlUeXl/CJ94w56eWhV7cd5ubfr6I11AHArU9t4EMz/vGcQkeHY/OhOqbnvfupIVtC7SzbXcX5E3PeVs8f1x4E4Nwh0rHdlUYfFZFB7fMXjGfzoToWbyrr9v03dxzhpodXMT4nhbdufT/fnT+d2qY2dkVGXm0JtfOdP27kw/e8yROrSrvdRnfPU63eX01tU9sJy+99eSef/s1ybvrdKlbuDXeSN7SEeG17BXnpCcwsyHiHf6l3FAQiMqhdNTufcTnJ/OKVnSecsA/XN/PFR1YzPjeZR79wNqPSE7h4WvjWzRc3lvHgm3s46/sv8ciy/QA8tqLkbZ93zvH5367kml+9RVt7x7Hlz60/yNW/fIvbn95wQj1LI88/vL6jgmvvW8JdL2zh079ZzqaDddx22Wn9+rcPlEFx+6iIyMkEA8Y/z5vAvz6xnle3VTBvSi4PvrmH17ZXUN8coqmtnV98/MxjdyjlZyRy/sQc7l68DQjP7/DZ88aytayeH76wlVe2HiYtMZaVe6tYvqeKv0X6H256eCWXnj6Kgswkvr5oHXExAV7cWMbh+mZGpCYA4UtQy/dU8fUPTObG88fx7SfXc99ru0mIDXDP9bO5bMbQHDZDo4+KyKDX1t7BvLtfJSc1nskjUni8yyWeH1w1g4+/5+3PF9U2tfHLV3aSmxrP584bRyBg1Da28ZFfvMn+qsZj6yXFBfny+yfR0BLinpd3Hls+JjuJn147i2t+tYRvfXAKX7xoIuV1zVz2szfITonj2VvOJyE2iHOOlfuqKcxMYlR6QvQPxLvQ0xATCgIRGRIWLt/PrU+FL9V85f2TCAaMSSNS3tYpfCoNLSEeXhKev+GCSTmkJMQcu7vpaEuI1fuq2V1xlMtmjGZEWgLX3beErWX1/OaGYu5evI11JbX86UvnMXFEalT+xmhSEIjIsLCupIaAGTMKBmbGtf2VjXzywWXHWhE/WTCLa+YMzSHRNB+BiAwLswozBnR/RdlJPPHP53D70xsZl5M8ZEPgVBQEIiI9GJGawAOf7vaL9LCh20dFRHxOQSAi4nMKAhERn1MQiIj4nIJARMTnFAQiIj6nIBAR8TkFgYiIzw25ISbMrALY53Ud/SgHOOJ1EUOMjlnf6Zj1zXA8XmOcc7ndvTHkgmC4MbOVJxv/Q7qnY9Z3OmZ947fjpUtDIiI+pyAQEfE5BYH37ve6gCFIx6zvdMz6xlfHS30EIiI+pxaBiIjPKQhERHxOQSAi4nMKgkHKzAJm9l9mdo+ZfcbreoYKM0s2s5Vm9mGvaxkKzOxKM3vAzB4zs0u8rmewivy7+m3kWH3C63r6m4IgCszsN2Z22Mw2Hrf8UjPbZmY7zezWU2zmCqAAaANKo1XrYNFPxwzg28Ci6FQ5uPTHMXPOPeOc+wJwM3BdNOsdbPp4/K4Gnogcq/kDXmyU6a6hKDCzC4GjwMPOudMjy4LAduADhE/sK4DrgSBw13Gb+Fzkp9o5d5+ZPeGc++hA1e+Ffjpms4BsIAE44px7bmCq90Z/HDPn3OHI534C/ME5t3qAyvdcH4/fFcALzrm1ZvaIc+7jHpUdFZq8Pgqcc6+b2djjFs8FdjrndgOY2ULgCufcXcAJlzHMrBRojbxsj2K5g0I/HbN5QDIwDWgys+edcx3RrNtL/XTMDPgh4ZOcb0IA+nb8CIdCAbCWYXglRUEwcPKBki6vS4H39LD+U8A9ZnYB8Ho0CxvE+nTMnHO3A5jZDYRbBMM2BHrQ139nXwIuBtLNbKJz7n+jWdwQcLLj93PgF2Z2OfAnLwqLJgXBIOWcawRu9LqOocg595DXNQwVzrmfEz7JSQ+ccw3AZ72uI1qGXRNnEDsAFHZ5XRBZJienY9Z3Ombvji+Pn4Jg4KwAJpnZODOLAz4GPOtxTYOdjlnf6Zi9O748fgqCKDCzR4ElwBQzKzWzG51zIeAWYDGwBVjknNvkZZ2DiY5Z3+mYvTs6fv+g20dFRHxOLQIREZ9TEIiI+JyCQETE5xQEIiI+pyAQEfE5BYGIiM8pCCTqzOzoAOzjZjP7dLT3c9w+rzSzae/wc3dEfv9PM/tm/1fXd2Y2z8x6HLHVzGaY2UMDVJIMEI01JEOGmQWdc92OxBqtwdJ62idwJfAcsLmPm/1XhuiY9s65DWZWYGZFzrn9Xtcj/UMtAhlQZvYtM1thZuvN7Ltdlj9jZqvMbJOZ3dRl+VEz+4mZrQPOibz+LzNbZ2ZLzWxkZL1j36zN7FUz+5GZLTez7ZERXDGzJDNbZGabzexpM1tmZsXd1Lg38vnVwAIz+0Kk5nVm9mRkO+cSPpnfbWZrzWxC5OfFyN/xhplN7Wbbk4EW59yRbt47I/I3rY/UlxlZflZk2Vozu9uOm0glss5oM3s9ss7GLn/zpWa2OlL73yLL5prZEjNbY2ZvmdmUbraXbOGJW5ZH1ruiy9t/Ijz0ggwTCgIZMBaeCnES4THfzwDmWHhyEAhPkjIHKAa+bGbZkeXJwDLn3Czn3JuR10udc7MID8/9hZPsLsY5Nxf4KvAfkWX/Qniyn2nAvwNzeii30jl3pnNuIfCUc+6syD63ADc6594iPAbNt5xzZzjndgH3A1+K/B3fBH7ZzXbPA0427v/DwLedczOBDV3q/j/gn5xzZ3DyuSk+DiyOrDMLWGtmucADwDWR2hdE1t0KXOCcmw3cAfygm+3dDrwcOYYXEQ685Mh7K4ELTlKHDEG6NCQD6ZLIz5rI6xTCwfA64ZP/VZHlhZHllYRPfE922UYr4csxAKsIzyTVnae6rDM28vv5wM8AnHMbzWx9D7U+1uX3083s+0BGpObFx69sZinAucDjZta5OL6b7Y4GKrr5fDqQ4Zx7LbLot5FtZQCpzrklkeWP0M0EM4QHS/uNmcUCz0Rm0poHvO6c2wPgnKuKrJsO/NbMJgEOiO1me5cA87v0XyQARYSD8DCQ181nZIhSEMhAMuAu59x9b1sYPmFdDJzjnGs0s1cJn3gAmo+7Rt/m/jFAVjsn/zfc0ot1etLQ5feHgCudc+ssPOnNvG7WDwA1kW/kPWkifCLuV5HZti4ELgceMrOfAtUnWf17wCvOuassPEPXq92sY4RbEtu6eS+B8N8hw4QuDclAWgx8LvLtGTPLN7MRhE+M1ZEQmAqcHaX9/x24NrLvacCMXn4uFTgU+bb9iS7L6yPv4ZyrA/aY2YLI9s3MZnWzrS3AxOMXOudqgerOa/vAp4DXnHM1QL2Zdc4y1u21eTMbA5Q75x4Afg2cCSwFLjSzcZF1siKrp/OPMfZvOMnfvBj4kkWaN2Y2u8t7k4ET+ilk6FIQyIBxzv2F8KWNJWa2AXiC8In0RSDGzLYQnj93aZRK+CWQa2abge8Dm4DaXnzu34FlhINka5flC4FvRTpTJxAOiRsjHdubCM91e7zXgdmdJ9jjfIbwtfj1hPtQ7owsvxF4wMzWEu4j6a7mecA6M1sDXAf8zDlXAdwEPBWpqfNy138Dd0XWPVlr6XuELxmtN7NNkdedLgL+fJLPyRCkYajFN8wsCMQ655ojJ+6XgCnOudYBruNnwJ+ccy/1cv0U59zRyO+3AqOdc1+JZo091BIPvAacHxm7X4YB9RGInyQBr0Qu8RjwLwMdAhE/oOcJ5Y93uZndRvi/132c/HLOQCgCblUIDC9qEYiI+Jz6CEREfE5BICLicwoCERGfUxCIiPicgkBExOcUBCIiPvf/ARo57AaMrA/YAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find(show_plot=True, max_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's train the model using the optimal learning rate. More accuracy is achieved after 4-5 epochs however to save time, we will run the cycle using 2 epochs only. That should give us ~93% accuracy and observed loss (binary crossentropy) of ~0.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_onecycle(8e-3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Autofit function can help optimally train the model without ``overfitting`` it. **Do not run** unless you are willing to spend days (or perhaps weeks) on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmjJwfrQv3Ex",
    "outputId": "17265489-ad02-4108-cb8d-549c06ff93f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping automatically enabled at patience=5\n",
      "reduce_on_plateau automatically enabled at patience=2\n",
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 1...\n",
      "Epoch 1/1024\n",
      "29479/29479 [==============================] - 147s 5ms/step - loss: 0.4999 - accuracy: 0.9536 - val_loss: 0.6889 - val_accuracy: 0.9551\n",
      "Epoch 2/1024\n",
      "29479/29479 [==============================] - 140s 5ms/step - loss: 0.7059 - accuracy: 0.9540 - val_loss: 0.6889 - val_accuracy: 0.9551\n",
      "Epoch 3/1024\n",
      "29479/29479 [==============================] - 134s 5ms/step - loss: 0.7059 - accuracy: 0.9540 - val_loss: 0.6889 - val_accuracy: 0.9551\n",
      "\n",
      "Epoch 00003: Reducing Max LR on Plateau: new max lr will be 0.5 (if not early_stopping).\n",
      "Epoch 4/1024\n",
      "29479/29479 [==============================] - 136s 5ms/step - loss: 0.7059 - accuracy: 0.9540 - val_loss: 0.6889 - val_accuracy: 0.9551\n",
      "Epoch 5/1024\n",
      "29479/29479 [==============================] - 132s 4ms/step - loss: 0.7059 - accuracy: 0.9540 - val_loss: 0.6889 - val_accuracy: 0.9551\n",
      "\n",
      "Epoch 00005: Reducing Max LR on Plateau: new max lr will be 0.25 (if not early_stopping).\n",
      "Epoch 6/1024\n",
      "29479/29479 [==============================] - 133s 5ms/step - loss: 0.7059 - accuracy: 0.9540 - val_loss: 0.6889 - val_accuracy: 0.9551\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Weights from best epoch have been loaded into model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb653b9cbe0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.autofit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alright, let's save our predictor so we can use it to perform inferences outside of the Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SAVED\n"
     ]
    }
   ],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)\n",
    "predictor.save('detector_nbsvm_plus')\n",
    "print('MODEL SAVED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's time for some fun! First, get a predictor instance that uses our pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.load_predictor('detector_trained_1m')\n",
    "new_model = ktrain.get_predictor(predictor.model, predictor.preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see if it can catch an XSS payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '<applet onkeydown=\"alert(1)\" contenteditable>test</applet>'\n",
    "result = new_model.predict(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can run more serious testing outside of the notebook"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ml_sqli_detector.ipynb",
   "provenance": []
  },
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-gpu-py38-cu112-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

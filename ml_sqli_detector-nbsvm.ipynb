{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic classifier that uses Distilbert model to predict if the payload is an SQL injection\n",
    "##### Distilbert is a smaller and faster version of BERT ( Bidirectional Encoder Representations from Transformers) that is 40% lighter while retaining 97% of BERT's language understanding ability. More on Distilbert at [HuggingFace](https://huggingface.co/docs/transformers/model_doc/distilbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To begin, let's install and import some packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9o-dl8wLv3Ep"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: ktrain in /usr/local/lib/python3.8/site-packages (0.31.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/site-packages (2.6.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (1.19.5)\n",
      "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.8/site-packages (from ktrain) (0.89.0)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.8/site-packages (from ktrain) (4.0.0)\n",
      "Requirement already satisfied: syntok==1.3.3 in /usr/local/lib/python3.8/site-packages (from ktrain) (1.3.3)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/site-packages (from ktrain) (0.1.96)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from ktrain) (21.3)\n",
      "Requirement already satisfied: cchardet in /usr/local/lib/python3.8/site-packages (from ktrain) (2.1.7)\n",
      "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.8/site-packages (from ktrain) (1.0.2)\n",
      "Requirement already satisfied: whoosh in /usr/local/lib/python3.8/site-packages (from ktrain) (2.7.4)\n",
      "Requirement already satisfied: scikit-learn==0.24.2 in /usr/local/lib/python3.8/site-packages (from ktrain) (0.24.2)\n",
      "Requirement already satisfied: langdetect in /usr/local/lib/python3.8/site-packages (from ktrain) (1.0.9)\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.8/site-packages (from ktrain) (0.42.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.8/site-packages (from ktrain) (1.2.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from ktrain) (2.25.1)\n",
      "Requirement already satisfied: transformers==4.10.3 in /usr/local/lib/python3.8/site-packages (from ktrain) (4.10.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/site-packages (from ktrain) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/site-packages (from scikit-learn==0.24.2->ktrain) (1.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn==0.24.2->ktrain) (3.0.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.8/site-packages (from syntok==1.3.3->ktrain) (2022.4.24)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.8/site-packages (from transformers==4.10.3->ktrain) (0.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/site-packages (from transformers==4.10.3->ktrain) (3.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from transformers==4.10.3->ktrain) (5.4.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/site-packages (from transformers==4.10.3->ktrain) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/site-packages (from transformers==4.10.3->ktrain) (4.62.3)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/site-packages (from transformers==4.10.3->ktrain) (0.0.53)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib) (8.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /usr/local/lib/python3.8/site-packages (from matplotlib) (6.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/site-packages (from matplotlib) (4.28.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.8/site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: keras-transformer==0.40.0 in /usr/local/lib/python3.8/site-packages (from keras-bert>=0.86.0->ktrain) (0.40.0)\n",
      "Requirement already satisfied: keras-multi-head==0.29.0 in /usr/local/lib/python3.8/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.29.0)\n",
      "Requirement already satisfied: keras-pos-embd==0.13.0 in /usr/local/lib/python3.8/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.13.0)\n",
      "Requirement already satisfied: keras-position-wise-feed-forward==0.8.0 in /usr/local/lib/python3.8/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.8.0)\n",
      "Requirement already satisfied: keras-embed-sim==0.10.0 in /usr/local/lib/python3.8/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: keras-layer-normalization==0.16.0 in /usr/local/lib/python3.8/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.16.0)\n",
      "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.8/site-packages (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.51.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/site-packages (from pandas>=1.0.1->ktrain) (2021.3)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib) (59.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->ktrain) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->ktrain) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->ktrain) (2021.10.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/site-packages (from sacremoses->transformers==4.10.3->ktrain) (8.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn>=1.0.0\n",
    "!pip3 install ktrain matplotlib tensorflow numpy\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some more imports...We are using ktrain wrapper to simplify model operations and take advantage of some cool stuff like simplified data set preprocessing, learning rate finding and \"autofit\" that ensures the model is not overfit. More details on ktrain here: [ktrain on GitHub](https://github.com/amaiya/ktrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "evreWp_bv3Es"
   },
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's print the list of available text classifiers in ktrain. There are relatively simple models like fasttext or bigru that have only 7-10 layers, as well as some more sophisticated deep models like BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.print_text_classifiers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Shmkj8niv3Ev"
   },
   "source": [
    "### Here, we will load our data set. \n",
    "##### We have a CSV file ``trainlist_22k.csv`` that contains a list of HTTP paths that are labeled according to their association with cross-site scripting (xss) and sql injection (sqli).  There is also a \"regular\" traffic that belongs to a \"benign\" class. Data set load is performed using the ```texts_from_csv``` method, which assumes the label_columns are already one-hot-encoded in the spreadsheet. Since *val_filepath* is None, 10% of the data will automatically be used as a validation set.\n",
    "##### In our set we have: 1 feature (payload), 1 label (type) that contains 3 classes:\n",
    " - xss\n",
    " - sqli\n",
    " - benign\n",
    "\n",
    "##### We will be using Distilbert model so preprocessing mode is set to ``Distilbert``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j6-wA79wv3Ew",
    "outputId": "7f7ba49d-d58f-4cf3-f363-806f37d2bd99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected encoding: UTF-8-SIG (if wrong, set manually)\n",
      "['attack', 'normal']\n",
      "         attack  normal\n",
      "701000      0.0     1.0\n",
      "481138      0.0     1.0\n",
      "1045499     0.0     1.0\n",
      "692395      0.0     1.0\n",
      "4869        0.0     1.0\n",
      "['attack', 'normal']\n",
      "        attack  normal\n",
      "883738     0.0     1.0\n",
      "168028     0.0     1.0\n",
      "586836     0.0     1.0\n",
      "383568     0.0     1.0\n",
      "214650     0.0     1.0\n",
      "language: en\n",
      "Word Counts: 568667\n",
      "Nrows: 943312\n",
      "943312 train sequences\n",
      "train sequence lengths:\n",
      "\tmean : 2\n",
      "\t95percentile : 6\n",
      "\t99percentile : 15\n",
      "x_train shape: (943312,200)\n",
      "y_train shape: (943312, 2)\n",
      "Is Multi-Label? False\n",
      "104813 test sequences\n",
      "test sequence lengths:\n",
      "\tmean : 2\n",
      "\t95percentile : 6\n",
      "\t99percentile : 15\n",
      "x_test shape: (104813,200)\n",
      "y_test shape: (104813, 2)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'trainlist_22k.csv'\n",
    "NUM_WORDS = 500\n",
    "MAXLEN = 200\n",
    "trn, val, preproc = text.texts_from_csv(DATA_PATH,\n",
    "                      'payload',\n",
    "                      label_columns = [\"type\"],\n",
    "                      val_filepath=None, # if None, 10% of data will be used for validation\n",
    "                      max_features=NUM_WORDS, maxlen=MAXLEN,\n",
    "                      ngram_range=1,\n",
    "                      preprocess_mode='standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load the learner instance that uses ```Distilbert``` model. We will retain the model structure unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "UpbaZ68Dv3Ew",
    "outputId": "68874f80-6a80-4960-a152-1b594f4ee856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "compiling word ID features...\n",
      "maxlen is 200\n",
      "building document-term matrix... this may take a few moments...\n",
      "rows: 1-10000\n",
      "rows: 10001-20000\n",
      "rows: 20001-30000\n",
      "rows: 30001-40000\n",
      "rows: 40001-50000\n",
      "rows: 50001-60000\n",
      "rows: 60001-70000\n",
      "rows: 70001-80000\n",
      "rows: 80001-90000\n",
      "rows: 90001-100000\n",
      "rows: 100001-110000\n",
      "rows: 110001-120000\n",
      "rows: 120001-130000\n",
      "rows: 130001-140000\n",
      "rows: 140001-150000\n",
      "rows: 150001-160000\n",
      "rows: 160001-170000\n",
      "rows: 170001-180000\n",
      "rows: 180001-190000\n",
      "rows: 190001-200000\n",
      "rows: 200001-210000\n",
      "rows: 210001-220000\n",
      "rows: 220001-230000\n",
      "rows: 230001-240000\n",
      "rows: 240001-250000\n",
      "rows: 250001-260000\n",
      "rows: 260001-270000\n",
      "rows: 270001-280000\n",
      "rows: 280001-290000\n",
      "rows: 290001-300000\n",
      "rows: 300001-310000\n",
      "rows: 310001-320000\n",
      "rows: 320001-330000\n",
      "rows: 330001-340000\n",
      "rows: 340001-350000\n",
      "rows: 350001-360000\n",
      "rows: 360001-370000\n",
      "rows: 370001-380000\n",
      "rows: 380001-390000\n",
      "rows: 390001-400000\n",
      "rows: 400001-410000\n",
      "rows: 410001-420000\n",
      "rows: 420001-430000\n",
      "rows: 430001-440000\n",
      "rows: 440001-450000\n",
      "rows: 450001-460000\n",
      "rows: 460001-470000\n",
      "rows: 470001-480000\n",
      "rows: 480001-490000\n",
      "rows: 490001-500000\n",
      "rows: 500001-510000\n",
      "rows: 510001-520000\n",
      "rows: 520001-530000\n",
      "rows: 530001-540000\n",
      "rows: 540001-550000\n",
      "rows: 550001-560000\n",
      "rows: 560001-570000\n",
      "rows: 570001-580000\n",
      "rows: 580001-590000\n",
      "rows: 590001-600000\n",
      "rows: 600001-610000\n",
      "rows: 610001-620000\n",
      "rows: 620001-630000\n",
      "rows: 630001-640000\n",
      "rows: 640001-650000\n",
      "rows: 650001-660000\n",
      "rows: 660001-670000\n",
      "rows: 670001-680000\n",
      "rows: 680001-690000\n",
      "rows: 690001-700000\n",
      "rows: 700001-710000\n",
      "rows: 710001-720000\n",
      "rows: 720001-730000\n",
      "rows: 730001-740000\n",
      "rows: 740001-750000\n",
      "rows: 750001-760000\n",
      "rows: 760001-770000\n",
      "rows: 770001-780000\n",
      "rows: 780001-790000\n",
      "rows: 790001-800000\n",
      "rows: 800001-810000\n",
      "rows: 810001-820000\n",
      "rows: 820001-830000\n",
      "rows: 830001-840000\n",
      "rows: 840001-850000\n",
      "rows: 850001-860000\n",
      "rows: 860001-870000\n",
      "rows: 870001-880000\n",
      "rows: 880001-890000\n",
      "rows: 890001-900000\n",
      "rows: 900001-910000\n",
      "rows: 910001-920000\n",
      "rows: 920001-930000\n",
      "rows: 930001-940000\n",
      "rows: 940001-943312\n",
      "computing log-count ratios...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, GaussianDropout, Flatten\n",
    "\n",
    "def get_model():\n",
    "    model = text.text_classifier('nbsvm', (trn), \n",
    "                             preproc=preproc)\n",
    "    #model.add(Dense(3, activation='sigmoid'))\n",
    "    #model.add(GaussianDropout1D(0.2))\n",
    "    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "nbsvm_model = get_model()\n",
    "new_model = Sequential()\n",
    "new_model.add(nbsvm_model)\n",
    "new_model.add(Dense(12, activation='sigmoid'))\n",
    "new_model.add(GaussianDropout(0.2))\n",
    "new_model.add(Dense(2, activation='sigmoid'))\n",
    "new_model.add(Flatten())\n",
    "new_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "learner = ktrain.get_learner(new_model, train_data=(trn), val_data=(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is what our model looks like. It has a number of layers that are pre-trained therefore allowing us to leverage transfer learning.\n",
    "##### Source code for modeling_tf_distilbert can be found at [HuggingFace Transformers](https://huggingface.co/transformers/v2.3.0/_modules/transformers/modeling_tf_distilbert.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fh1_l7ioIpS6",
    "outputId": "c35e8957-540f-42a7-fd07-d9d417915873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (trainable=True) : <keras.engine.functional.Functional object at 0x7fb6610aad90>\n",
      "1 (trainable=True) : <keras.layers.core.Dense object at 0x7fb6610aae20>\n",
      "2 (trainable=True) : <keras.layers.noise.GaussianDropout object at 0x7fb657473fd0>\n",
      "3 (trainable=True) : <keras.layers.core.Dense object at 0x7fb654f72c40>\n",
      "4 (trainable=True) : <keras.layers.core.Flatten object at 0x7fb654f72ca0>\n"
     ]
    }
   ],
   "source": [
    "learner.print_layers()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to ensure that majority of existing pre-trained layers are not re-trained so we are freezing those with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ATgiIbyE7XJ"
   },
   "outputs": [],
   "source": [
    "learner.freeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The optimal learning rate for this model can be found using the **lr_find** function however it will take at least **20 minutes!** on this VM that uses CPU only. ( Optimal rate was found to be 3e-5 and therefore there is no need to spend time on this now). **If you still want to proceed**, uncomment the command and run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "u-kza8Env3Ex",
    "outputId": "146052d1-5d60-4708-b878-1660db206379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Epoch 1/5\n",
      "29479/29479 [==============================] - 89s 3ms/step - loss: 0.4979 - accuracy: 0.9400\n",
      "Epoch 2/5\n",
      "29479/29479 [==============================] - 89s 3ms/step - loss: 0.2616 - accuracy: 0.9540\n",
      "Epoch 3/5\n",
      "29479/29479 [==============================] - 90s 3ms/step - loss: 0.0520 - accuracy: 0.9836\n",
      "Epoch 4/5\n",
      "29479/29479 [==============================] - 90s 3ms/step - loss: 0.0494 - accuracy: 0.9896\n",
      "Epoch 5/5\n",
      "29479/29479 [==============================] - 27s 921us/step - loss: 0.1201 - accuracy: 0.9751\n",
      "\n",
      "\n",
      "done.\n",
      "Visually inspect loss plot and select learning rate associated with falling loss\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find(show_plot=True, max_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's train the model using the optimal learning rate. More accuracy is achieved after 4-5 epochs however to save time, we will run the cycle using 2 epochs only. That should give us ~93% accuracy and observed loss (binary crossentropy) of ~0.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_onecycle(8e-3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Autofit function can help optimally train the model without ``overfitting`` it. **Do not run** unless you are willing to spend days (or perhaps weeks) on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmjJwfrQv3Ex",
    "outputId": "17265489-ad02-4108-cb8d-549c06ff93f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping automatically enabled at patience=5\n",
      "reduce_on_plateau automatically enabled at patience=2\n",
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 0.008...\n",
      "Epoch 1/1024\n",
      "29479/29479 [==============================] - 108s 4ms/step - loss: 0.0458 - accuracy: 0.9896 - val_loss: 0.0266 - val_accuracy: 0.9946\n",
      "Epoch 2/1024\n",
      "29479/29479 [==============================] - 106s 4ms/step - loss: 0.0304 - accuracy: 0.9942 - val_loss: 0.0273 - val_accuracy: 0.9945\n",
      "Epoch 3/1024\n",
      "29479/29479 [==============================] - 107s 4ms/step - loss: 0.0297 - accuracy: 0.9942 - val_loss: 0.0258 - val_accuracy: 0.9948\n",
      "Epoch 4/1024\n",
      "29479/29479 [==============================] - 108s 4ms/step - loss: 0.0294 - accuracy: 0.9944 - val_loss: 0.0262 - val_accuracy: 0.9947\n",
      "Epoch 5/1024\n",
      "29479/29479 [==============================] - 106s 4ms/step - loss: 0.0292 - accuracy: 0.9944 - val_loss: 0.0263 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00005: Reducing Max LR on Plateau: new max lr will be 0.004 (if not early_stopping).\n",
      "Epoch 6/1024\n",
      "29479/29479 [==============================] - 105s 4ms/step - loss: 0.0279 - accuracy: 0.9945 - val_loss: 0.0256 - val_accuracy: 0.9945\n",
      "Epoch 7/1024\n",
      "29479/29479 [==============================] - 106s 4ms/step - loss: 0.0273 - accuracy: 0.9945 - val_loss: 0.0251 - val_accuracy: 0.9946\n",
      "Epoch 8/1024\n",
      "29479/29479 [==============================] - 107s 4ms/step - loss: 0.0275 - accuracy: 0.9945 - val_loss: 0.0257 - val_accuracy: 0.9945\n",
      "Epoch 9/1024\n",
      "29479/29479 [==============================] - 109s 4ms/step - loss: 0.0271 - accuracy: 0.9944 - val_loss: 0.0254 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00009: Reducing Max LR on Plateau: new max lr will be 0.002 (if not early_stopping).\n",
      "Epoch 10/1024\n",
      "29479/29479 [==============================] - 111s 4ms/step - loss: 0.0264 - accuracy: 0.9946 - val_loss: 0.0252 - val_accuracy: 0.9945\n",
      "Epoch 11/1024\n",
      "29479/29479 [==============================] - 106s 4ms/step - loss: 0.0261 - accuracy: 0.9946 - val_loss: 0.0251 - val_accuracy: 0.9945\n",
      "Epoch 12/1024\n",
      "29479/29479 [==============================] - 115s 4ms/step - loss: 0.0260 - accuracy: 0.9945 - val_loss: 0.0255 - val_accuracy: 0.9943\n",
      "Epoch 13/1024\n",
      "29479/29479 [==============================] - 108s 4ms/step - loss: 0.0262 - accuracy: 0.9946 - val_loss: 0.0249 - val_accuracy: 0.9945\n",
      "Epoch 14/1024\n",
      "29479/29479 [==============================] - 107s 4ms/step - loss: 0.0262 - accuracy: 0.9946 - val_loss: 0.0251 - val_accuracy: 0.9943\n",
      "Epoch 15/1024\n",
      "29479/29479 [==============================] - 107s 4ms/step - loss: 0.0263 - accuracy: 0.9946 - val_loss: 0.0252 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00015: Reducing Max LR on Plateau: new max lr will be 0.001 (if not early_stopping).\n",
      "Epoch 16/1024\n",
      "29479/29479 [==============================] - 106s 4ms/step - loss: 0.0258 - accuracy: 0.9947 - val_loss: 0.0253 - val_accuracy: 0.9944\n",
      "Epoch 17/1024\n",
      "29479/29479 [==============================] - 106s 4ms/step - loss: 0.0258 - accuracy: 0.9947 - val_loss: 0.0253 - val_accuracy: 0.9944\n",
      "\n",
      "Epoch 00017: Reducing Max LR on Plateau: new max lr will be 0.0005 (if not early_stopping).\n",
      "Epoch 18/1024\n",
      "29479/29479 [==============================] - 106s 4ms/step - loss: 0.0256 - accuracy: 0.9948 - val_loss: 0.0253 - val_accuracy: 0.9944\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Weights from best epoch have been loaded into model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb68f353340>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.autofit(8e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alright, let's save our predictor so we can use it to perform inferences outside of the Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SAVED\n"
     ]
    }
   ],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)\n",
    "predictor.save('detector_nbsvm')\n",
    "print('MODEL SAVED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's time for some fun! First, get a predictor instance that uses our pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.load_predictor('detector_trained_1m')\n",
    "new_model = ktrain.get_predictor(predictor.model, predictor.preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see if it can catch an XSS payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '<applet onkeydown=\"alert(1)\" contenteditable>test</applet>'\n",
    "result = new_model.predict(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can run more serious testing outside of the notebook"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ml_sqli_detector.ipynb",
   "provenance": []
  },
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-gpu-py38-cu112-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
